{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "84e13b8f",
   "metadata": {},
   "source": [
    "# 최종 점검"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cba2e2b",
   "metadata": {},
   "source": [
    "### 1. ReLU 함수 사용할 때 주로 쓰는 가중치 초깃값은??"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "479be11b",
   "metadata": {},
   "source": [
    "$$\\sqrt{2 \\over n}\\$$\n",
    "(He initialization)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cb9f401",
   "metadata": {},
   "source": [
    "### 2. 이진 분류 문제를 모델링할 때, 출력층에서 무슨 함수를 쓰는 것이 적합할까?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e230186",
   "metadata": {},
   "source": [
    "시그모이드 함수"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc997a87",
   "metadata": {},
   "source": [
    "### 3. Optimizer 예를 3가지 들어라"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d1531eb",
   "metadata": {},
   "source": [
    "GD(Gradient Descent): 기울기 이용<br>\n",
    "Momentum: exponentially weighted average 이용, <br>\n",
    "AdaGrad: learning rate decay 이용, 학습률을 조정"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b76d906c",
   "metadata": {},
   "source": [
    "### 4. One-Hot encoding이란 무엇인가?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44442269",
   "metadata": {},
   "source": [
    "선택지의 개수의 차원을 가지는 벡터에서 원하는 선택지의 원소를 1, 나머지 선택지의 원소는 0이 되도록 하는 표현 방법"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73eaa7cc",
   "metadata": {},
   "source": [
    "### 5. Opencv로 이미지 데이터들을 numpy array로 만들었다. 이 데이터들을 모두 같은 크기 (640x800)으로 만들기 위해 필요한 함수는?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecf82444",
   "metadata": {},
   "source": [
    "cv2.resize(name, dsize, interpolation)\n",
    "* numpy.reshape의 경우 전체 크기 변경이 불가함\n",
    "* numpy.resize의 경우 크기가 변경될 경우 크기를 강제로 변경함 (의도치 않은 원소 반복 발생 가능)\n",
    "* cv2.resize의 경우 interpolation 설정 가능함"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "63ab4666",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries for 5)\n",
    "import os\n",
    "import cv2\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfb85684",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Test code\n",
    "base = '/Users/seolyumin/Downloads/cats/'\n",
    "for file_name in os.listdir(base):\n",
    "    path = base + file_name\n",
    "    if '.jpg' in path:\n",
    "        im = cv2.imread(path, 0)\n",
    "        im_res = cv2.resize(im, (640, 800))\n",
    "        print(\"original size:\", im.shape, \"changed size:\", im_res.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a7758be",
   "metadata": {},
   "source": [
    "### 6. Tensorflow로 CNN모델을 설계하고 코드를 설명할 것(조건 이외에는 자유)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04ee4661",
   "metadata": {},
   "source": [
    "조건 1) class로 구현<br>\n",
    "조건 2) batch normalization 구현<br>\n",
    "조건 3) Xavier 초깃값 구현<br>\n",
    "조건 4) 최소 3개 이상의 layer 구현<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d65af556",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "848a2d4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# MNIST 숫자 손글씨 데이터셋을 가지고 여러 모델을 구현한 후 가장 정확도가 높았던 모델을 선정\n",
    "class CNN(tf.keras.Model):\n",
    "    def __init__(self):\n",
    "        super(CNN, self).__init__()\n",
    "        # 3 convolutional layers, and fully connected layer at the end\n",
    "        # Activation: ReLU(with He), Sigmoid(with Xavier)\n",
    "        self.conv1 = tf.keras.layers.Conv2D(filters=32, kernel_size=5, strides=1, padding='same', kernel_initializer='he_normal', activation='relu')\n",
    "        self.pool1 = tf.keras.layers.MaxPool2D(padding='same')\n",
    "        self.conv2 = tf.keras.layers.Conv2D(filters=64, kernel_size=5, strides=1, padding='same', kernel_initializer='he_normal', activation='relu')\n",
    "        self.pool2 = tf.keras.layers.MaxPool2D(padding='same')\n",
    "        self.conv3 = tf.keras.layers.Conv2D(filters=128, kernel_size=3, strides=1, padding='same', kernel_initializer='he_normal', activation='relu')\n",
    "        self.pool3 = tf.keras.layers.MaxPool2D(padding='same')\n",
    "        self.flatten = tf.keras.layers.Flatten()\n",
    "        self.dense1 = tf.keras.layers.Dense(units=256, kernel_initializer='he_normal', activation='relu')\n",
    "        self.dropout = tf.keras.layers.Dropout(rate=0.4)\n",
    "        self.dense2 = tf.keras.layers.Dense(units=10, kernel_initializer='glorot_normal', activation='sigmoid') # Xavier normalization\n",
    "        self.BN = tf.keras.layers.BatchNormalization()\n",
    "    def call(self, input_data, training=False):\n",
    "        # Convolutional layer 1 - Convolution(32, 3) -> ReLU(He) -> Batch Norm. -> Pooling\n",
    "        res = self.conv1(input_data)\n",
    "        res = self.BN(res)\n",
    "        res = self.pool1(res)\n",
    "        # Convolutional layer 2 - Convolution(64, 3) -> ReLU(He) -> Batch Norm. -> Pooling\n",
    "        res = self.conv2(res)\n",
    "        res = self.BN(res)\n",
    "        res = self.pool2(res)\n",
    "        # Convolutional layer 3 - Convolution(128, 3) -> ReLU(He) -> Batch Norm. -> Pooling\n",
    "        res = self.conv3(res)\n",
    "        res = self.BN(res)\n",
    "        res = self.pool3(res)\n",
    "        # Fully connected layer part\n",
    "        res = self.flatten(res)\n",
    "        res = self.dense1(res)\n",
    "        res = self.BN(res)\n",
    "        res = self.dropout(res)\n",
    "        res = self.dense2(res)\n",
    "        return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e3ea4938",
   "metadata": {},
   "outputs": [],
   "source": [
    "# MNIST 데이터셋 불러오기\n",
    "(train_images, train_labels), (test_images, test_labels) = tf.keras.datasets.mnist.load_data()\n",
    "train_images = np.reshape(train_images, (60000, 28, 28, 1))\n",
    "train_images = train_images.astype(np.float32) / 255. # 0과 1 사이의 값으로 변환"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a0347a5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_images = np.reshape(test_images, (10000, 28, 28, 1))\n",
    "test_images = test_images.astype(np.float32) / 255. # 0과 1 사이의 값으로 변환"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14e617fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shape 변경 확인\n",
    "train_images[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "cccd42e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1500/1500 [==============================] - 44s 29ms/step - loss: 0.1165 - accuracy: 0.9639 - val_loss: 0.0415 - val_accuracy: 0.9872\n",
      "Epoch 2/10\n",
      "1500/1500 [==============================] - 47s 31ms/step - loss: 0.0508 - accuracy: 0.9840 - val_loss: 0.0439 - val_accuracy: 0.9872\n",
      "Epoch 3/10\n",
      "1500/1500 [==============================] - 48s 32ms/step - loss: 0.0368 - accuracy: 0.9880 - val_loss: 0.0338 - val_accuracy: 0.9897\n",
      "Epoch 4/10\n",
      "1500/1500 [==============================] - 52s 35ms/step - loss: 0.0312 - accuracy: 0.9904 - val_loss: 0.0357 - val_accuracy: 0.9899\n",
      "Epoch 5/10\n",
      "1500/1500 [==============================] - 51s 34ms/step - loss: 0.0274 - accuracy: 0.9910 - val_loss: 0.0385 - val_accuracy: 0.9893\n",
      "Epoch 6/10\n",
      "1500/1500 [==============================] - 50s 33ms/step - loss: 0.0219 - accuracy: 0.9932 - val_loss: 0.0425 - val_accuracy: 0.9882\n",
      "Epoch 7/10\n",
      "1500/1500 [==============================] - 49s 33ms/step - loss: 0.0176 - accuracy: 0.9945 - val_loss: 0.0290 - val_accuracy: 0.9920\n",
      "Epoch 8/10\n",
      "1500/1500 [==============================] - 51s 34ms/step - loss: 0.0146 - accuracy: 0.9950 - val_loss: 0.0359 - val_accuracy: 0.9908\n",
      "Epoch 9/10\n",
      "1500/1500 [==============================] - 52s 34ms/step - loss: 0.0135 - accuracy: 0.9955 - val_loss: 0.0369 - val_accuracy: 0.9903\n",
      "Epoch 10/10\n",
      "1500/1500 [==============================] - 51s 34ms/step - loss: 0.0130 - accuracy: 0.9957 - val_loss: 0.0296 - val_accuracy: 0.9923\n",
      "Model: \"sequential_5\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_13 (Conv2D)           (32, 28, 28, 32)          320       \n",
      "_________________________________________________________________\n",
      "batch_normalization_13 (Batc (32, 28, 28, 32)          128       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_13 (MaxPooling (32, 14, 14, 32)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_14 (Conv2D)           (32, 14, 14, 64)          18496     \n",
      "_________________________________________________________________\n",
      "batch_normalization_14 (Batc (32, 14, 14, 64)          256       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_14 (MaxPooling (32, 7, 7, 64)            0         \n",
      "_________________________________________________________________\n",
      "conv2d_15 (Conv2D)           (32, 7, 7, 128)           73856     \n",
      "_________________________________________________________________\n",
      "batch_normalization_15 (Batc (32, 7, 7, 128)           512       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_15 (MaxPooling (32, 4, 4, 128)           0         \n",
      "_________________________________________________________________\n",
      "flatten_5 (Flatten)          (32, 2048)                0         \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (32, 256)                 524544    \n",
      "_________________________________________________________________\n",
      "batch_normalization_16 (Batc (32, 256)                 1024      \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (32, 256)                 0         \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (32, 10)                  2570      \n",
      "=================================================================\n",
      "Total params: 621,706\n",
      "Trainable params: 620,746\n",
      "Non-trainable params: 960\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# 약식 모델 train\n",
    "model5 = tf.keras.Sequential([\n",
    "    # Convolutional layer 1 - Convolution(32, 3) -> ReLU(He) -> Batch Norm. -> Pooling\n",
    "    tf.keras.layers.Conv2D(filters=32, kernel_size=3, padding='same', kernel_initializer='he_normal', activation='relu'),\n",
    "    tf.keras.layers.BatchNormalization(),\n",
    "    tf.keras.layers.MaxPool2D(padding='same'),\n",
    "    # Convolutional layer 2 - Convolution(64, 3) -> ReLU(He) -> Batch Norm. -> Pooling\n",
    "    tf.keras.layers.Conv2D(filters=64, kernel_size=3, padding='same', kernel_initializer='he_normal', activation='relu'),\n",
    "    tf.keras.layers.BatchNormalization(),\n",
    "    tf.keras.layers.MaxPool2D(padding='same'),\n",
    "    # Convolutional layer 3 - Convolution(128, 3) -> ReLU(He) -> Batch Norm. -> Pooling\n",
    "    tf.keras.layers.Conv2D(filters=128, kernel_size=3, padding='same', kernel_initializer='he_normal', activation='relu'),\n",
    "    tf.keras.layers.BatchNormalization(),\n",
    "    tf.keras.layers.MaxPool2D(padding='same'),\n",
    "    # Fully connected layer part - Flatten -> Dense(256) -> ReLU(He) -> Batch Norm. -> Dropout(0.4) -> Dense(10)\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(units=256, kernel_initializer='he_normal', activation='relu'),\n",
    "    tf.keras.layers.BatchNormalization(),\n",
    "    tf.keras.layers.Dropout(rate=0.4),\n",
    "    tf.keras.layers.Dense(units=10, kernel_initializer='glorot_normal', activation='sigmoid')\n",
    "])\n",
    "model5.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "model5.fit(train_images, train_labels, epochs=10, validation_split=0.2)\n",
    "model5.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ab35d821",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 3s 8ms/step - loss: 0.0279 - accuracy: 0.9928\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.027936438098549843, 0.9927999973297119]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 약식 모델 test\n",
    "model5.evaluate(test_images, test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9388f6c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
